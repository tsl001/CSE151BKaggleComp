{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do List\n",
    "1) ~~Need to extract agent-id from pickle files to a variable~~\\\n",
    "2) ~~Need to extract track-id from pickle files to a variable~~\\\n",
    "3) ~~Need to extract car mask from pickle files to a variable~~\\\n",
    "4) Need to use extracted agent-id and match with the correct track-id to monitor that track-id's predictions\\\n",
    "5) ~~Need to use car mask to get only the track-id's that have objects~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "import math\n",
    "import csv\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"./new_train/new_train\"\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset = ArgoverseDataset(data_path=train_path)\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_collate definition for train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collate(batch): \n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    #car_masks = numpy.array(car_masks)\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    #actual_objects = track_id[car_mask.reshape([-1]).astype(int)] #track id actually used\n",
    "    \n",
    "    #actual_objects = []\n",
    "    #actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    '''for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "    \n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []'''\n",
    "    \n",
    "    \n",
    "    for i in range(len(car_masks)):\n",
    "        mask = numpy.count_nonzero(car_masks[i])\n",
    "        inp_relevant.append(inp[i, :mask, :, :])\n",
    "        out_relevant.append(out[i, :mask, :, :])\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(track_ids),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "    \n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    return [inp, out,scenes_indices,agent_indices,car_masks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val_collate definition for val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    \n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    actual_objects = [] #track id actually used\n",
    "    actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(track_ids),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    return [inp, scenes_indices,agent_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train_loader and val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_collate, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=val_collate, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"This class defines your deep learning model that extends a Module class\n",
    "      The constructor of your class defines the layers of the model. \n",
    "      The forward() function defines how to forward propagate \n",
    "      input through the defined layers of the model.\n",
    "      Many layers are available, such as Linear for fully connected layers, \n",
    "      Conv2d for convolutional layers, and MaxPool2d for pooling layers.\n",
    "\n",
    "    \"\"\"\n",
    "    #============================================\n",
    "    # TODO: Implement CNN model.\n",
    "    #=============================================\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4,1000,5) #it's 4*60 because there's 60 vehicles and we're just looking at it's present features [pos_x,pos_y,vel_x,vel_y]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(1000)\n",
    "        self.conv2 = nn.Conv2d(1000,30,5)\n",
    "        self.fc1 = nn.Linear(30 * 1 * 12, 1000)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(30)\n",
    "        self.fc2 = nn.Linear(1000,1000)\n",
    "        self.fc3 = nn.Linear(1000, 60 * 30 * 4)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    '''\n",
    "        1) Understand dataset correctly (input shape and output shape etc.)\n",
    "        2) \n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        #print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x))) #F.relu(self.conv1(x))\n",
    "        x = self.batchNorm1(x)\n",
    "        #print(\"xshape in forward after batchNorm1: \",x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"xshape in forward after conv2: \",x.shape)\n",
    "        #x = self.batchNorm2(x)\n",
    "        \n",
    "        x = x.view(-1, 30 * 1 * 12)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"xshape in forward after one fc1: \",x.shape)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def train(model, device, train_batch, optimizer, epoch,log_interval=10000):\n",
    "    model.train()\n",
    "    #iterator = tqdm(train_batch, total=int(len(train_batch)))\n",
    "    #counter = 0\n",
    "    \n",
    "    data,target,scenes_indices,agent_indices = train_batch\n",
    "    data = data.to(device)\n",
    "    #target = target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    #print(len(train_batch))\n",
    "    data = data.type(torch.FloatTensor)\n",
    "    #print(len(data)\n",
    "    \n",
    "    #data = torch.reshape(data,(len(data),60 * 19 * 4))\n",
    "    data = torch.reshape(data,(len(data),4,60,19)) \n",
    "    target = target.type(torch.FloatTensor)\n",
    "    target = torch.reshape(target,(len(data),60 * 30 * 4)) \n",
    "    output = model(data)\n",
    "    #print(len(data))\n",
    "    outputPickleFormat = torch.reshape(output,(len(data),60,30,4))\n",
    "    #print(outputPickleFormat)\n",
    "    target = target.to(device)\n",
    "    #output = torch.reshape(output,(1,60 * 30 * 4))\n",
    "    targetPickleFormat = torch.reshape(target,(len(data),60,30,4))\n",
    "\n",
    "    \n",
    "    '''\n",
    "    #calculate loss with respect to the agent's movements\n",
    "    agent_batch_out = []\n",
    "    agent_batch_target = []\n",
    "\n",
    "    for scene_out,scene_target,agent_idx in zip(outputPickleFormat,targetPickleFormat,agent_indices):\n",
    "        agent_batch_out.append(scene_out[agent_idx].tolist())\n",
    "        agent_batch_target.append(scene_target[agent_idx].tolist())\n",
    "\n",
    "    agent_batch_out = torch.tensor(agent_batch_out,requires_grad=True)\n",
    "    agent_batch_target = torch.tensor(agent_batch_target,requires_grad=True)\n",
    "\n",
    "    agent_batch_out = agent_batch_out.to(device)\n",
    "    agent_batch_target = agent_batch_target.to(device)\n",
    "    '''\n",
    "    \n",
    "    loss = torch.mean((target-output)**2)**0.5\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "    #counter += 1\n",
    "    #torch.cuda.empty_cache()\n",
    "    #iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "    #histogram for x and y input positions of train's agents\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_batch,epoch):#target_loader,epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictedPos = []\n",
    "    predPosArr = []\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        data,scenes_indices,agent_indices = test_batch\n",
    "        data = data.to(device)\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        #data = torch.reshape(data,(len(data),60 * 19 * 4))\n",
    "        data = torch.reshape(data,(len(data),4,60,19))\n",
    "        output = model(data)\n",
    "        #output = torch.reshape(output,(len(data),60 * 30 * 4))\n",
    "        outputPickleFormat = torch.reshape(output,(len(data),60,30,4))\n",
    "       \n",
    "        #Get target agent's pos x and pos y to put into csv for submission later on\n",
    "        agent_batch_out = []\n",
    "        agent_predicted_vals = []\n",
    "        for scene_out,agent_idx,scene_idx in zip(outputPickleFormat,agent_indices,scenes_indices):\n",
    "            for time_step in scene_out[agent_idx]:\n",
    "                agent_predicted_vals.append(time_step[0].item())\n",
    "                agent_predicted_vals.append(time_step[1].item())\n",
    "            agent_predicted_vals.insert(0,scene_idx)\n",
    "            agent_batch_out.append(agent_predicted_vals)\n",
    "            agent_predicted_vals = []\n",
    "\n",
    "    return agent_batch_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write CSV header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "with open('submissionCNN.csv','w',newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    headerRow = []\n",
    "    \n",
    "    headerRow.append(\"ID\")\n",
    "    for i in range(1,61):\n",
    "        headerRow.append(\"v\" + str(i))\n",
    "        \n",
    "    thewriter.writerow(headerRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show_sample_batch function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out,scenes_indices = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of histogram plots for input and output for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainInOutPos(inp_posx_arr,inp_posy_arr,out_posx_arr,out_posy_arr,out_vel_arr,out_vel_target_arr,bins_cnt):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_posx_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Input x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_posy_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Input y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    #histogram for x and y output positions of train's agents\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_posx_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Output x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_posy_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Output y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_vel_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Velocity out magnitudes distribution\")\n",
    "    plt.xlabel(\"Velocity Magnitudes\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_vel_target_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Velocity out magnitudes distribution for target agents\")\n",
    "    plt.xlabel(\"Velocity Magnitudes\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(loss_arr,epoch):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.plot(loss_arr,'r')\n",
    "    plt.title(\"Loss graph after epoch \" + str(epoch))\n",
    "    plt.xlabel(\"indices\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda chosen\n",
      "Number of batches to iterate through for training dataset:  805\n",
      "Batch size:  256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3c88636fc948a5b7009773d92322f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=805.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"<ipython-input-4-655512422ef1>\", line 31, in train_collate\n    inp_relevant.append(inp[i, :mask, :, :])\nTypeError: list indices must be integers or slices, not tuple\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4810b019a53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0miterator_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Begin training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0minp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenes_indices_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent_indices_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"<ipython-input-4-655512422ef1>\", line 31, in train_collate\n    inp_relevant.append(inp[i, :mask, :, :])\nTypeError: list indices must be integers or slices, not tuple\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda chosen\")\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    print(\"cpu chosen\")\n",
    "    dev = \"cpu\"\n",
    "        \n",
    "device = dev\n",
    "model = CNN().cuda() #using cpu here\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epoch = 10\n",
    "\n",
    "\n",
    "inp_posx_hist = []\n",
    "inp_posy_hist = []\n",
    "out_posx_hist = []\n",
    "out_posy_hist = []\n",
    "out_vel_hist = []\n",
    "out_vel_target_hist = []\n",
    "\n",
    "training_samples_target_posx = []\n",
    "training_samples_target_posy = []\n",
    "training_samples_target_velx = []\n",
    "training_samples_target_vely = []\n",
    "training_samples_pred_in =  []\n",
    "training_samples_pred_out_posx = []\n",
    "training_samples_pred_out_posy = []\n",
    "training_samples_pred_out_velx = []\n",
    "training_samples_pred_out_vely = []\n",
    "loss_arr = []\n",
    "\n",
    "print(\"Number of batches to iterate through for training dataset: \",len(train_loader))\n",
    "print(\"Batch size: \",batch_sz)\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    iterator_train = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    \n",
    "    for i_batch, train_batch in enumerate(iterator_train): #Begin training \n",
    "        if epoch == 1:\n",
    "            inp_train, out_train, scenes_indices_train,agent_indices_train = train_batch\n",
    "            #print(inp_train.shape)\n",
    "            for scene_in,scene_out,agent_idx in zip(inp_train,out_train,agent_indices_train):\n",
    "                for idx,(vehicle_in,vehicle_out) in enumerate(zip(scene_in,scene_out)):\n",
    "                        inp_posx_hist.append(vehicle_in[18][0].item())\n",
    "                        inp_posy_hist.append(vehicle_in[18][1].item())\n",
    "                        out_posx_hist.append(vehicle_out[18][0].item())\n",
    "                        out_posy_hist.append(vehicle_out[18][1].item())\n",
    "                        out_vel_hist.append(((vehicle_out[18][2].item())**2 + (vehicle_out[18][3].item())**2)**0.5)\n",
    "                        if idx == agent_idx:\n",
    "                            out_vel_target_hist.append(((vehicle_out[18][2].item())**2 + (vehicle_out[18][3].item())**2)**0.5)\n",
    "        \n",
    "        if(i_batch < 2) and epoch == 1:\n",
    "            for scene_in,scene_out in zip(inp_train,out_train):\n",
    "                scene_out = torch.reshape(scene_out,(1,len(scene_out),30,4))\n",
    "                scene_out = scene_out.type(torch.FloatTensor)\n",
    "                for vehicles in scene_out[0]:\n",
    "                    for time_step in vehicles:\n",
    "                        training_samples_target_posx.append(time_step[0].item())\n",
    "                        training_samples_target_posy.append(time_step[1].item())\n",
    "                        training_samples_target_velx.append(time_step[2].item())\n",
    "                        training_samples_target_vely.append(time_step[3].item())\n",
    "\n",
    "                scene_in = torch.reshape(scene_in,(1,len(scene_in),19,4))\n",
    "                training_samples_pred_in.append(scene_in)\n",
    "                \n",
    "        add_loss = train(model, device, train_batch, optimizer, epoch) #replace train_loader with our input training data\n",
    "        loss_arr.append(add_loss)\n",
    "        #print(\"add_loss raw: \",add_loss)\n",
    "        #print(\"add_loss averaged: \",add_loss / len(train_batch))\n",
    "    \n",
    "    \n",
    "    print(\"Done with training on epoch \",epoch)\n",
    "    plotLoss(loss_arr,epoch)\n",
    "    \n",
    "    \n",
    "    if epoch == 1:\n",
    "        plotTrainInOutPos(inp_posx_hist,inp_posy_hist,out_posx_hist,out_posy_hist,out_vel_hist,out_vel_target_hist,1000)\n",
    "    \n",
    "    #Begin testing\n",
    "    iterator_test = tqdm(val_loader,total=int(len(val_loader)))\n",
    "    for i_batch,test_batch in enumerate(iterator_test):\n",
    "        predicted_batches = test(model, device, test_batch,epoch)\n",
    "        \n",
    "        if epoch == num_epoch: #if done with the last epoch then we write to file\n",
    "            with open('submission.csv','a',newline='') as f: #append to csv\n",
    "                thewriter = csv.writer(f)\n",
    "                for p_list in predicted_batches:\n",
    "                    thewriter.writerow(p_list)\n",
    "    \n",
    "    \n",
    "    print(\"Done with epoch \",epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
