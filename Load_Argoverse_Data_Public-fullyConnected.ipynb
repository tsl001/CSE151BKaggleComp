{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do List\n",
    "1) ~~Need to extract agent-id from pickle files to a variable~~\\\n",
    "2) ~~Need to extract track-id from pickle files to a variable~~\\\n",
    "3) ~~Need to extract car mask from pickle files to a variable~~\\\n",
    "4) Need to use extracted agent-id and match with the correct track-id to monitor that track-id's predictions\\\n",
    "5) ~~Need to use car mask to get only the track-id's that have objects~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "import math\n",
    "import csv\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"./new_train/new_train\"\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset = ArgoverseDataset(data_path=train_path)\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_collate definition for train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_collate(batch): \n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    #print(batch[0]['car_mask'])\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    #agent_id = batch[0]['agent_id']\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    #car_mask = batch[0]['car_mask']\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    #actual_objects = track_id[car_mask.reshape([-1]).astype(int)] #track id actually used\n",
    "    actual_objects = []\n",
    "    actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(actual_objects),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "    \n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    return [inp, out,scenes_indices,agent_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val_collate definition for val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    \n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    actual_objects = [] #track id actually used\n",
    "    actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(actual_objects),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    return [inp, scenes_indices,agent_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train_loader and val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_collate, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=val_collate, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \"\"\"This class defines your deep learning model that extends a Module class\n",
    "      The constructor of your class defines the layers of the model. \n",
    "      The forward() function defines how to forward propagate \n",
    "      input through the defined layers of the model.\n",
    "      Many layers are available, such as Linear for fully connected layers, \n",
    "      Conv2d for convolutional layers, and MaxPool2d for pooling layers.\n",
    "\n",
    "    \"\"\"\n",
    "    #============================================\n",
    "    # TODO: Implement Fully Connected Network model.\n",
    "    #=============================================\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4,100,3) #it's 4*60 because there's 60 vehicles and we're just looking at it's present features [pos_x,pos_y,vel_x,vel_y]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100,60,1)\n",
    "        self.fc1 = nn.Linear(60 * 19 * 4, 500)\n",
    "        self.batchNorm2 = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(500, 450)\n",
    "        self.fc3 = nn.Linear(450, 60 * 30 * 4)\n",
    "        self.softMax = nn.LogSoftmax()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    '''\n",
    "        1) Understand dataset correctly (input shape and output shape etc.)\n",
    "        2) \n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        #x = x.to(self.device)\n",
    "        x = x.cuda()\n",
    "        #x = self.pool(F.relu(self.conv1(x)))#F.relu(self.conv1(x))\n",
    "        #x = self.batchNorm1(x)\n",
    "        #print(\"xshape in forward after batchNorm1: \",x.shape)\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"xshape in forward after conv2: \",x.shape)\n",
    "        \n",
    "        #x = x.view(-1, 60 * 19 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"xshape in forward after one fc1: \",x.shape)\n",
    "        #x = self.batchNorm2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = self.softMax(x) #Need to add this because training and testing use nll_loss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_batch, optimizer, epoch,log_interval=10000):\n",
    "    model.train()\n",
    "    #iterator = tqdm(train_batch, total=int(len(train_batch)))\n",
    "    #counter = 0\n",
    "    \n",
    "    data,target,scenes_indices,agent_indices = train_batch\n",
    "    data = data.to(device)\n",
    "    #target = target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    #print(len(train_batch))\n",
    "    data = data.type(torch.FloatTensor)\n",
    "    #print(len(data)\n",
    "    \n",
    "    data = torch.reshape(data,(len(data),60 * 19 * 4))\n",
    "    target = target.type(torch.FloatTensor)\n",
    "    target = torch.reshape(target,(len(data),60 * 30 * 4)) \n",
    "    output = model(data)\n",
    "    \n",
    "    outputPickleFormat = torch.reshape(output,(len(data),60,30,4))\n",
    "\n",
    "    target = target.to(device)\n",
    "    #output = torch.reshape(output,(1,60 * 30 * 4))\n",
    "    targetPickleFormat = torch.reshape(target,(len(data),60,30,4))\n",
    "\n",
    "    \n",
    "    '''\n",
    "    #calculate loss with respect to the agent's movements\n",
    "    agent_batch_out = []\n",
    "    agent_batch_target = []\n",
    "\n",
    "    for scene_out,scene_target,agent_idx in zip(outputPickleFormat,targetPickleFormat,agent_indices):\n",
    "        agent_batch_out.append(scene_out[agent_idx].tolist())\n",
    "        agent_batch_target.append(scene_target[agent_idx].tolist())\n",
    "\n",
    "    agent_batch_out = torch.tensor(agent_batch_out,requires_grad=True)\n",
    "    agent_batch_target = torch.tensor(agent_batch_target,requires_grad=True)\n",
    "\n",
    "    agent_batch_out = agent_batch_out.to(device)\n",
    "    agent_batch_target = agent_batch_target.to(device)\n",
    "    '''\n",
    "    \n",
    "    loss = torch.mean((targetPickleFormat-outputPickleFormat)**2)**0.5\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "    #counter += 1\n",
    "    #torch.cuda.empty_cache()\n",
    "    #iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "    #histogram for x and y input positions of train's agents\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_batch,epoch):#target_loader,epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictedPos = []\n",
    "    predPosArr = []\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        data,scenes_indices,agent_indices = test_batch\n",
    "        data = data.to(device)\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        data = torch.reshape(data,(len(data),60 * 19 * 4))\n",
    "        output = model(data)\n",
    "        output = torch.reshape(output,(len(data),60 * 30 * 4))\n",
    "        outputPickleFormat = torch.reshape(output,(len(data),60,30,4))\n",
    "       \n",
    "\n",
    "        #Get target agent's pos x and pos y to put into csv for submission later on\n",
    "        agent_batch_out = []\n",
    "        agent_predicted_vals = []\n",
    "        for scene_out,agent_idx,scene_idx in zip(outputPickleFormat,agent_indices,scenes_indices):\n",
    "            for time_step in scene_out[agent_idx]:\n",
    "                agent_predicted_vals.append(time_step[0])\n",
    "                agent_predicted_vals.append(time_step[1])\n",
    "            agent_predicted_vals.insert(0,scene_idx)\n",
    "            agent_batch_out.append(agent_predicted_vals)\n",
    "            agent_predicted_vals = []\n",
    "\n",
    "    return agent_batch_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write CSV header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "with open('submission.csv','w',newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    headerRow = []\n",
    "    \n",
    "    headerRow.append(\"ID\")\n",
    "    for i in range(1,61):\n",
    "        headerRow.append(\"v\" + str(i))\n",
    "        \n",
    "    thewriter.writerow(headerRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show_sample_batch function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out,scenes_indices = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of histogram plots for input and output for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainInOutPos(inp_posx_arr,inp_posy_arr,out_posx_arr,out_posy_arr,out_vel_arr,out_vel_target_arr):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_posx_arr,edgecolor='black',log='true')\n",
    "    plt.title(\"Input x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_posy_arr,edgecolor='black',log='true')\n",
    "    plt.title(\"Input y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    #histogram for x and y output positions of train's agents\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_posx_arr,edgecolor='black',log='true')\n",
    "    plt.title(\"Output x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_posy_arr,edgecolor='black',log='true')\n",
    "    plt.title(\"Output y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_vel_arr,edgecolor='black',log='true')\n",
    "    plt.title(\"Velocity out magnitudes distribution\")\n",
    "    plt.xlabel(\"Velocity Magnitudes\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_vel_target_arr,edgecolor='black',log='true')\n",
    "    plt.title(\"Velocity out magnitudes distribution for target agents\")\n",
    "    plt.xlabel(\"Velocity Magnitudes\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(loss_arr):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.plot(loss_arr,'r')\n",
    "    plt.title(\"Loss graph\")\n",
    "    plt.xlabel(\"indices\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda chosen\n",
      "805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b64d87f9c364f4b893645c3d8d3afe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=805.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0ae7d02da6427ebfd714064b191e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([60, 19, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-190571eaaae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample_pred_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_samples_pred_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_samples_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_pred_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msample_pred_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_pred_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mtraining_samples_pred_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_pred_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b28d3ec6fd2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#x = x.view(-1, 60 * 19 * 4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m#print(\"xshape in forward after one fc1: \",x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#x = self.batchNorm2(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda chosen\")\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    print(\"cpu chosen\")\n",
    "    dev = \"cpu\"\n",
    "        \n",
    "device = dev\n",
    "model = FullyConnectedNet().cuda() #using cpu here\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epoch = 10\n",
    "\n",
    "\n",
    "inp_posx_hist = []\n",
    "inp_posy_hist = []\n",
    "out_posx_hist = []\n",
    "out_posy_hist = []\n",
    "out_vel_hist = []\n",
    "out_vel_target_hist = []\n",
    "\n",
    "training_samples_target = []\n",
    "training_samples_pred_in =  []\n",
    "training_samples_pred_out = []\n",
    "loss_arr = []\n",
    "\n",
    "print(len(train_loader))\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    iterator_train = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    iterator_test = tqdm(val_loader,total=int(len(val_loader)))\n",
    "    \n",
    "    for i_batch, train_batch in enumerate(iterator_train): #Begin training \n",
    "        if epoch == 1:\n",
    "            inp_train, out_train, scenes_indices_train,agent_indices_train = train_batch\n",
    "            #print(inp_train.shape)\n",
    "            for scene_in,scene_out,agent_idx in zip(inp_train,out_train,agent_indices_train):\n",
    "                for idx,(vehicle_in,vehicle_out) in enumerate(zip(scene_in,scene_out)):\n",
    "                        inp_posx_hist.append(vehicle_in[18][0].item())\n",
    "                        inp_posy_hist.append(vehicle_in[18][1].item())\n",
    "                        out_posx_hist.append(vehicle_out[18][0].item())\n",
    "                        out_posy_hist.append(vehicle_out[18][1].item())\n",
    "                        out_vel_hist.append(((vehicle_out[18][2].item())**2 + (vehicle_out[18][3].item())**2)**0.5)\n",
    "                        if idx == agent_idx:\n",
    "                            out_vel_target_hist.append(((vehicle_out[18][2].item())**2 + (vehicle_out[18][3].item())**2)**0.5)\n",
    "        \n",
    "        if(i_batch < 2) and epoch == 1:\n",
    "            for scene_in,scene_out in zip(inp_train,out_train):\n",
    "                scene_out = torch.reshape(scen)\n",
    "                training_samples_target.append(scene_out)\n",
    "                training_samples_pred_in.append(scene_in)\n",
    "                \n",
    "        add_loss = train(model, device, train_batch, optimizer, epoch) #replace train_loader with our input training data\n",
    "        loss_arr.append(add_loss)\n",
    "        #print(\"add_loss raw: \",add_loss)\n",
    "        #print(\"add_loss averaged: \",add_loss / len(train_batch))\n",
    "    \n",
    "    for sample_pred_in in training_samples_pred_in:\n",
    "        print(sample_pred_in.shape)\n",
    "        sample_pred_in = torch.reshape(sample_pred_in,(1,60*19*4)) #need to reshape to this for our model\n",
    "        sample_pred_out = model(sample_pred_in) #will have size 1x (60*30*4)\n",
    "        sample_pred_out = torch.reshape(sample_pred_out,(1,60,30,4))\n",
    "        training_samples_pred_out.append(sample_pred_out)\n",
    "        \n",
    "    print(\"Done with training\")\n",
    "    plotLoss(loss_arr)\n",
    "    \n",
    "    \n",
    "    if epoch == 1:\n",
    "        plotTrainInOutPos(inp_posx_hist,inp_posy_hist,out_posx_hist,out_posy_hist,out_vel_hist,out_vel_target_hist)\n",
    "    \n",
    "    #Begin testing\n",
    "    for i_batch,test_batch in enumerate(iterator_test):\n",
    "        predicted_batches = test(model, device, test_batch,epoch)\n",
    "        \n",
    "        if epoch == num_epoch: #if done with the last epoch then we write to file\n",
    "            with open('submission.csv','a',newline='') as f: #append to csv\n",
    "                thewriter = csv.writer(f)\n",
    "                for p_list in predicted_batches:\n",
    "                    thewriter.writerow(p_list)\n",
    "    \n",
    "    \n",
    "    print(\"Done with one epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
