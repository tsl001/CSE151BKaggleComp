{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do List\n",
    "1) ~~Need to extract agent-id from pickle files to a variable~~\\\n",
    "2) ~~Need to extract track-id from pickle files to a variable~~\\\n",
    "3) ~~Need to extract car mask from pickle files to a variable~~\\\n",
    "4) Need to use extracted agent-id and match with the correct track-id to monitor that track-id's predictions\\\n",
    "5) ~~Need to use car mask to get only the track-id's that have objects~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "import math\n",
    "import csv\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"./new_train/new_train\"\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset = ArgoverseDataset(data_path=train_path)\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_collate definition for train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_collate(batch): \n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    #print(batch[0]['car_mask'])\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    #agent_id = batch[0]['agent_id']\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    #car_mask = batch[0]['car_mask']\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    #actual_objects = track_id[car_mask.reshape([-1]).astype(int)] #track id actually used\n",
    "    actual_objects = []\n",
    "    actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(actual_objects),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "    \n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "        #print(\"Confirmation of correct agent_index\",agent_id,\" : \",track[agent_index])\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    return [inp, out,scenes_indices,agent_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val_collate definition for val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    \n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    actual_objects = [] #track id actually used\n",
    "    actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(actual_objects),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    return [inp, scenes_indices,agent_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train_loader and val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_collate, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=val_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"This class defines your deep learning model that extends a Module class\n",
    "      The constructor of your class defines the layers of the model. \n",
    "      The forward() function defines how to forward propagate \n",
    "      input through the defined layers of the model.\n",
    "      Many layers are available, such as Linear for fully connected layers, \n",
    "      Conv2d for convolutional layers, and MaxPool2d for pooling layers.\n",
    "\n",
    "    \"\"\"\n",
    "    #============================================\n",
    "    # TODO: Implement CNN model.\n",
    "    #=============================================\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4,100,3) #it's 4*60 because there's 60 vehicles and we're just looking at it's present features [pos_x,pos_y,vel_x,vel_y]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100,60,1)\n",
    "        self.fc1 = nn.Linear(60 * 19 * 4, 120)\n",
    "        self.batchNorm2 = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 60 * 30 * 4)\n",
    "        self.softMax = nn.LogSoftmax()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    '''\n",
    "        1) Understand dataset correctly (input shape and output shape etc.)\n",
    "        2) \n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        #x = self.pool(F.relu(self.conv1(x)))#F.relu(self.conv1(x))\n",
    "        #x = self.batchNorm1(x)\n",
    "        #print(\"xshape in forward after batchNorm1: \",x.shape)\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"xshape in forward after conv2: \",x.shape)\n",
    "        \n",
    "        #x = x.view(-1, 60 * 19 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"xshape in forward after one fc1: \",x.shape)\n",
    "        #x = self.batchNorm2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = self.softMax(x) #Need to add this because training and testing use nll_loss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = train_loader.to(device)\\n    target = target_loader.to(device)\\n    optimizer.zero_grad()\\n    \\n    #data = data.type(torch.FloatTensor)\\n    output = model(data)\\n    print(output.shape)\\n    print(output)\\n    loss = torch.mean((output-target)**2)\\n    loss.backward()\\n    optimizer.step()\\n    print(output)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch,log_interval=10000):\n",
    "    model.train()\n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    inp_arr_posx_train = []\n",
    "    inp_arr_posy_train = []\n",
    "    out_arr_posx_train = []\n",
    "    out_arr_posy_train= []\n",
    "    \n",
    "    for batch_idx, (data,target,scenes_indices,agent_indices) in enumerate(iterator):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if epoch == 1:\n",
    "            for data_scene,target_scene in zip(data,target):\n",
    "                for data_vehicle,target_vehicle in zip(data_scene,target_scene):\n",
    "                    inp_arr_posx_train.append(data_vehicle[18][0])\n",
    "                    inp_arr_posy_train.append(data_vehicle[18][1])\n",
    "                    out_arr_posx_train.append(target_vehicle[18][0])\n",
    "                    out_arr_posy_train.append(target_vehicle[18][1])\n",
    "            \n",
    "        \n",
    "        data = data.type(torch.FloatTensor)\n",
    "        data = torch.reshape(data,(train_loader.batch_size,60 * 19 * 4))\n",
    "        #data = torch.reshape(data,(1,4,60,19)) #used with convolutional layers\n",
    "        target = target.type(torch.FloatTensor)\n",
    "        target = torch.reshape(target,(train_loader.batch_size,60 * 30 * 4)) \n",
    "        #print(\"data in train tranposed:\",data.shape)\n",
    "        output = model(data)\n",
    "        output = output.to(device)\n",
    "        outputPickleFormat = torch.reshape(output,(train_loader.batch_size,60,30,4))\n",
    "        #print(outputPickleFormat[0][agent_index])\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #output = torch.reshape(output,(1,60 * 30 * 4))\n",
    "        targetPickleFormat = torch.reshape(target,(train_loader.batch_size,60,30,4))\n",
    "        #print(targetPickleFormat[0][agent_index])\n",
    "\n",
    "        #calculate loss with respect to the agent's movements\n",
    "        runningLoss = 0\n",
    "        for batch_i,agent_index in enumerate(agent_indices):\n",
    "            loss = torch.sqrt(torch.mean((outputPickleFormat[batch_i][agent_index]-targetPickleFormat[batch_i][agent_index])**2))\n",
    "            runningLoss += loss\n",
    "            \n",
    "        loss = runningLoss / len(agent_indices)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        #print(loss.item())\n",
    "        iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "        #print(loss.item())\n",
    "    #histogram for x and y input positions of train's agents\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_arr_posx_train,edgecolor='black')\n",
    "    plt.title(\"Input x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_arr_posy_train,edgecolor='black')\n",
    "    plt.title(\"Input y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    #histogram for x and y output positions of train's agents\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_arr_posx_train,edgecolor='black')\n",
    "    plt.title(\"Output x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_arr_posy_train,edgecolor='black')\n",
    "    plt.title(\"Output y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "'''data = train_loader.to(device)\n",
    "    target = target_loader.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #data = data.type(torch.FloatTensor)\n",
    "    output = model(data)\n",
    "    print(output.shape)\n",
    "    print(output)\n",
    "    loss = torch.mean((output-target)**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(output)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader,epoch):#target_loader,epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictedPos = []\n",
    "    predPosArr = []\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data,scenes_indices,agent_indices in test_loader:\n",
    "            \n",
    "            data = data.to(device)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            #data = torch.reshape(data,(1,4,60,19))\n",
    "            data = torch.reshape(data,(test_loader.batch_size,60 * 19 * 4))\n",
    "            output = model(data)\n",
    "            #print(output)\n",
    "            output = torch.reshape(output,(test_loader.batch_size,60 * 30 * 4))\n",
    "            outputPickleFormat = torch.reshape(output,(test_loader.batch_size,60,30,4))\n",
    "            #print(outputPickleFormat)\n",
    "            \n",
    "            for batch,scene_index in zip(outputPickleFormat,scenes_indices):\n",
    "                for vehicle in batch:\n",
    "                    predicted_x = vehicle[29][0] #should give us the predicted 30th time step's pos x\n",
    "                    predicted_y = vehicle[29][1] #should give us the predicted 30th time step's pos y\n",
    "                    predictedPos.append(math.sqrt((predicted_x**2) + (predicted_y**2)))\n",
    "                predictedPos.insert(0,scene_index)\n",
    "                scenes_indices.remove(scene_index)\n",
    "                predPosArr.append(predictedPos)\n",
    "                predictedPos = []\n",
    "        \n",
    "    return predPosArr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write CSV header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "with open('submission.csv','w',newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    headerRow = []\n",
    "    \n",
    "    headerRow.append(\"ID\")\n",
    "    for i in range(1,61):\n",
    "        headerRow.append(\"v\" + str(i))\n",
    "        \n",
    "    thewriter.writerow(headerRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show_sample_batch function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out,scenes_indices = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda chosen\n",
      "6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dac6279e86a4e96ae5ba528fa651a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6436.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.92 GiB total capacity; 9.93 GiB already allocated; 17.50 MiB free; 358.04 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6eacdfc64d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpredictedList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#replace train_loader with our input training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpredictedList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f42206b2dcb5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscenes_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.92 GiB total capacity; 9.93 GiB already allocated; 17.50 MiB free; 358.04 MiB cached)"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda chosen\")\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    print(\"cpu chosen\")\n",
    "    dev = \"cpu\"\n",
    "        \n",
    "device = dev\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epoch = 10\n",
    "\n",
    "print(len(train_loader))\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    #for i_batch, train_batch in enumerate(train_loader): #Begin training\n",
    "        #inp_train, out_train, scenes_indices_train,agent_indices_train = train_batch\n",
    "    \n",
    "\n",
    "    predictedList = []\n",
    "\n",
    "    train(model, device, train_loader, optimizer, epoch) #replace train_loader with our input training data\n",
    "    predictedList = test(model, device, val_loader,epoch)   \n",
    "\n",
    "    if epoch == num_epoch: #if done with the last epoch then we write to file\n",
    "        with open('submission.csv','a',newline='') as f: #append to csv\n",
    "            thewriter = csv.writer(f)\n",
    "            for p_list in predictedList:\n",
    "                thewriter.writerow(p_list)\n",
    "    '''plt.style.use('fivethirtyeight')\n",
    "    plt.plot(loss_arr,'r')\n",
    "    plt.title(\"Loss graph\")\n",
    "    plt.xlabel(\"indices\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()'''\n",
    "    \n",
    "    print(\"Done with one epoch\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#for j_batch,val_batch in enumerate(val_loader): #Begin testing\n",
    "    #inp_val, scenes_indices_val,agent_indices_val = val_batch\n",
    "\n",
    "    #print(scenes_indices)\n",
    "    #print(sample_batch)\n",
    "\n",
    "                          #momentum=momentum)#,weight_decay=1)\n",
    "    #rowList = []\n",
    "    #batchList = []\n",
    "\n",
    "    #for inp_arr_val,scene_idx_val,agent_idx_val in zip(inp_val,scenes_indices_val,agent_indices_val):\n",
    "       # rowList = test(model, device, inp_arr_val,epoch,agent_idx_val)#,out_arr_test,epoch) #replace test_loader with our input test data\n",
    "        #rowList.insert(0,scene_idx_val)\n",
    "        #if(epoch == num_epoch): #if at the last epoch then we'll add onto the list that we'll write to csv\n",
    "            #batchList.append(rowList)\n",
    "\n",
    "    #if(epoch == num_epoch):\n",
    "        #with open('submission.csv','a',newline='') as f: #append to csv\n",
    "            #thewriter = csv.writer(f)\n",
    "            #for predictedList in batchList:\n",
    "                #thewriter.writerow(predictedList)\n",
    "\n",
    "\n",
    "    #Show sample batch on graph\n",
    "    #show_sample_batch(train_batch, agent_id)\n",
    "    #write to csv\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"Done with training\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
