{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do List\n",
    "1) Try out regularizer,dropouts,etc.\\\n",
    "2) Try out learning rate scheduling e.g. start at 0.01 lr then after 2 epochs reduce to 0.0001 for lr\\\n",
    "3) Try out different batch sizes\\\n",
    "4) Try out different architecture if done everything to minimize loss in current arch. such as adding more layers,neurons,etc.\\\n",
    "5) If step 4 doesn't work anymore need to change model to say CNN or LSTM etc.\\\n",
    "6) Use common/well known model architectures first for example for CNN use ResNet,AlexNet,LeNet,etc.\\\n",
    "7) Start with small networks first for the common model architectures e.g AlexNet with 5-6 layers\n",
    "8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "import math\n",
    "import csv\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"./new_train/new_train\"\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset = ArgoverseDataset(data_path=train_path)\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_collate definition for train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collate(batch): \n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    #print(batch[0]['car_mask'])\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    #agent_id = batch[0]['agent_id']\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    #car_mask = batch[0]['car_mask']\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    #actual_objects = track_id[car_mask.reshape([-1]).astype(int)] #track id actually used\n",
    "    actual_objects = []\n",
    "    actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(actual_objects),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "    \n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    print(inp)\n",
    "    return [inp, out,scenes_indices,agent_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val_collate definition for val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    \n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_masks = [scene['car_mask'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    \n",
    "    actual_objects = [] #track id actually used\n",
    "    actual_obj = []\n",
    "    agent_indices = []\n",
    "    \n",
    "    for c_mask,t_id in zip(car_masks,track_ids): #use only tracks that have vehicles on it, if no vehicle present it's labelled as -1\n",
    "        for mask,track in zip(c_mask,t_id):\n",
    "            if mask[0] == 1:\n",
    "                actual_obj.append(track[0][0])\n",
    "            else:\n",
    "                actual_obj.append(-1)\n",
    "        actual_objects.append(actual_obj)\n",
    "        actual_obj = []\n",
    "    \n",
    "    for (i,track),agent_id in zip(enumerate(actual_objects),agent_ids): #will look through the tracks with vehicles and see which one is the agent's track\n",
    "        for j,tr in enumerate(track):\n",
    "            if tr == agent_id:\n",
    "                agent_index = j\n",
    "                break\n",
    "        agent_indices.append(agent_index)\n",
    "    \n",
    "    inp = torch.LongTensor(inp)\n",
    "\n",
    "    scenes_indices = [scene['scene_idx'] for scene in batch]\n",
    "    return [inp, scenes_indices,agent_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train_loader and val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_collate, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=val_collate, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \"\"\"This class defines your deep learning model that extends a Module class\n",
    "      The constructor of your class defines the layers of the model. \n",
    "      The forward() function defines how to forward propagate \n",
    "      input through the defined layers of the model.\n",
    "      Many layers are available, such as Linear for fully connected layers, \n",
    "      Conv2d for convolutional layers, and MaxPool2d for pooling layers.\n",
    "\n",
    "    \"\"\"\n",
    "    #============================================\n",
    "    # TODO: Implement Fully Connected Network model.\n",
    "    #=============================================\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4,100,3) #it's 4*60 because there's 60 vehicles and we're just looking at it's present features [pos_x,pos_y,vel_x,vel_y]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100,60,1)\n",
    "        self.fc1 = nn.Linear(60 * 19 * 4, 17500)\n",
    "        self.batchNorm2 = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(17500,17500)\n",
    "        self.fc3 = nn.Linear(17500, 60 * 30 * 4)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dropOut1 = nn.Dropout(p=0.5)\n",
    "        self.dropOut2 = nn.Dropout(p=0.35)\n",
    "        self.dropOut3 = nn.Dropout(p=0.4)\n",
    "        \n",
    "    '''\n",
    "        1) Understand dataset correctly (input shape and output shape etc.)\n",
    "        2) \n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        #x = x.cuda()\n",
    "        #x = self.pool(F.relu(self.conv1(x)))#F.relu(self.conv1(x))\n",
    "        #x = self.batchNorm1(x)\n",
    "        #print(\"xshape in forward after batchNorm1: \",x.shape)\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"xshape in forward after conv2: \",x.shape)\n",
    "        \n",
    "        #x = x.view(-1, 60 * 19 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropOut1(x)\n",
    "        #print(\"xshape in forward after one fc1: \",x.shape)\n",
    "        #x = self.batchNorm2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropOut1(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_batch, optimizer, epoch,log_interval=10000):\n",
    "    model.train()\n",
    "    #iterator = tqdm(train_batch, total=int(len(train_batch)))\n",
    "    #counter = 0\n",
    "    \n",
    "    data,target,scenes_indices,agent_indices = train_batch\n",
    "    data = data.to(device)\n",
    "    #target = target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    #print(len(train_batch))\n",
    "    data = data.type(torch.FloatTensor)\n",
    "    #print(len(data)\n",
    "    \n",
    "    data = torch.reshape(data,(len(data),60 * 19 * 4))\n",
    "    target = target.type(torch.FloatTensor)\n",
    "    target = torch.reshape(target,(len(data),60 * 30 * 4)) \n",
    "    output = model(data)\n",
    "    \n",
    "    '''\n",
    "    output = batch_size x (60 * 30 * 4)\n",
    "    \n",
    "    '''\n",
    "    outputPickleFormat = torch.reshape(output,(len(data),60,30,4))\n",
    "\n",
    "    target = target.to(device)\n",
    "    #output = torch.reshape(output,(1,60 * 30 * 4))\n",
    "    targetPickleFormat = torch.reshape(target,(len(data),60,30,4))\n",
    "\n",
    "    \n",
    "    '''\n",
    "    #calculate loss with respect to the agent's movements\n",
    "    agent_batch_out = []\n",
    "    agent_batch_target = []\n",
    "\n",
    "    for scene_out,scene_target,agent_idx in zip(outputPickleFormat,targetPickleFormat,agent_indices):\n",
    "        agent_batch_out.append(scene_out[agent_idx].tolist())\n",
    "        agent_batch_target.append(scene_target[agent_idx].tolist())\n",
    "\n",
    "    agent_batch_out = torch.tensor(agent_batch_out,requires_grad=True)\n",
    "    agent_batch_target = torch.tensor(agent_batch_target,requires_grad=True)\n",
    "\n",
    "    agent_batch_out = agent_batch_out.to(device)\n",
    "    agent_batch_target = agent_batch_target.to(device)\n",
    "    '''\n",
    "    \n",
    "    loss = torch.mean((targetPickleFormat-outputPickleFormat)**2)**0.5\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "    #counter += 1\n",
    "    #torch.cuda.empty_cache()\n",
    "    #iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "    #histogram for x and y input positions of train's agents\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_batch,epoch):#target_loader,epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictedPos = []\n",
    "    predPosArr = []\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        data,scenes_indices,agent_indices = test_batch\n",
    "        data = data.to(device)\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        data = torch.reshape(data,(len(data),60 * 19 * 4))\n",
    "        output = model(data)\n",
    "        #output = torch.reshape(output,(len(data),60 * 30 * 4))\n",
    "        outputPickleFormat = torch.reshape(output,(len(data),60,30,4))\n",
    "       \n",
    "\n",
    "        #Get target agent's pos x and pos y to put into csv for submission later on\n",
    "        agent_batch_out = []\n",
    "        agent_predicted_vals = []\n",
    "        for scene_out,agent_idx,scene_idx in zip(outputPickleFormat,agent_indices,scenes_indices):\n",
    "            for time_step in scene_out[agent_idx]:\n",
    "                agent_predicted_vals.append(time_step[0].item())\n",
    "                agent_predicted_vals.append(time_step[1].item())\n",
    "            agent_predicted_vals.insert(0,scene_idx)\n",
    "            agent_batch_out.append(agent_predicted_vals)\n",
    "            agent_predicted_vals = []\n",
    "\n",
    "    return agent_batch_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write CSV header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "with open('submission.csv','w',newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    headerRow = []\n",
    "    \n",
    "    headerRow.append(\"ID\")\n",
    "    for i in range(1,61):\n",
    "        headerRow.append(\"v\" + str(i))\n",
    "        \n",
    "    thewriter.writerow(headerRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show_sample_batch function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out,scenes_indices = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of histogram plots for input and output for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainInOutPos(inp_posx_arr,inp_posy_arr,out_posx_arr,out_posy_arr,out_vel_arr,out_vel_target_arr,bins_cnt):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_posx_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Input x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(inp_posy_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Input y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    #histogram for x and y output positions of train's agents\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_posx_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Output x-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"x-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_posy_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Output y-axis distribution for all agents in training\")\n",
    "    plt.xlabel(\"y-position\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_vel_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Velocity out magnitudes distribution\")\n",
    "    plt.xlabel(\"Velocity Magnitudes\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.hist(out_vel_target_arr,bins=bins_cnt,edgecolor='black',log='true')\n",
    "    plt.title(\"Velocity out magnitudes distribution for target agents\")\n",
    "    plt.xlabel(\"Velocity Magnitudes\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(loss_arr,epoch):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.plot(loss_arr,'r')\n",
    "    plt.title(\"Loss graph after epoch \" + str(epoch))\n",
    "    plt.xlabel(\"indices\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda chosen\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 306.00 MiB (GPU 0; 10.92 GiB total capacity; 41.50 KiB already allocated; 146.50 MiB free; 1.96 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7605f61ba087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullyConnectedNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#using cpu here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 306.00 MiB (GPU 0; 10.92 GiB total capacity; 41.50 KiB already allocated; 146.50 MiB free; 1.96 MiB cached)"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda chosen\")\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    print(\"cpu chosen\")\n",
    "    dev = \"cpu\"\n",
    "        \n",
    "device = dev\n",
    "model = FullyConnectedNet().cuda() #using cpu here\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epoch = 10\n",
    "\n",
    "\n",
    "inp_posx_hist = []\n",
    "inp_posy_hist = []\n",
    "out_posx_hist = []\n",
    "out_posy_hist = []\n",
    "out_vel_hist = []\n",
    "out_vel_target_hist = []\n",
    "\n",
    "training_samples_target_posx = []\n",
    "training_samples_target_posy = []\n",
    "training_samples_target_velx = []\n",
    "training_samples_target_vely = []\n",
    "training_samples_pred_in =  []\n",
    "training_samples_pred_out_posx = []\n",
    "training_samples_pred_out_posy = []\n",
    "training_samples_pred_out_velx = []\n",
    "training_samples_pred_out_vely = []\n",
    "loss_arr = []\n",
    "\n",
    "print(\"Number of batches to iterate through for training dataset: \",len(train_loader))\n",
    "print(\"Batch size: \",batch_sz)\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    iterator_train = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    \n",
    "    for i_batch, train_batch in enumerate(iterator_train): #Begin training \n",
    "        if epoch == 1:\n",
    "            inp_train, out_train, scenes_indices_train,agent_indices_train = train_batch\n",
    "            #print(inp_train.shape)\n",
    "            for scene_in,scene_out,agent_idx in zip(inp_train,out_train,agent_indices_train):\n",
    "                for idx,(vehicle_in,vehicle_out) in enumerate(zip(scene_in,scene_out)):\n",
    "                        inp_posx_hist.append(vehicle_in[18][0].item())\n",
    "                        inp_posy_hist.append(vehicle_in[18][1].item())\n",
    "                        out_posx_hist.append(vehicle_out[18][0].item())\n",
    "                        out_posy_hist.append(vehicle_out[18][1].item())\n",
    "                        out_vel_hist.append(((vehicle_out[18][2].item())**2 + (vehicle_out[18][3].item())**2)**0.5)\n",
    "                        if idx == agent_idx:\n",
    "                            out_vel_target_hist.append(((vehicle_out[18][2].item())**2 + (vehicle_out[18][3].item())**2)**0.5)\n",
    "        \n",
    "        if(i_batch < 2) and epoch == 1:\n",
    "            for scene_in,scene_out in zip(inp_train,out_train):\n",
    "                scene_out = torch.reshape(scene_out,(1,60,30,4))\n",
    "                scene_out = scene_out.type(torch.FloatTensor)\n",
    "                for vehicles in scene_out[0]:\n",
    "                    for time_step in vehicles:\n",
    "                        training_samples_target_posx.append(time_step[0].item())\n",
    "                        training_samples_target_posy.append(time_step[1].item())\n",
    "                        training_samples_target_velx.append(time_step[2].item())\n",
    "                        training_samples_target_vely.append(time_step[3].item())\n",
    "\n",
    "                scene_in = torch.reshape(scene_in,(1,60,19,4))\n",
    "                training_samples_pred_in.append(scene_in)\n",
    "                \n",
    "        add_loss = train(model, device, train_batch, optimizer, epoch) #replace train_loader with our input training data\n",
    "        loss_arr.append(add_loss)\n",
    "        #print(\"add_loss raw: \",add_loss)\n",
    "        #print(\"add_loss averaged: \",add_loss / len(train_batch))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if epoch == 1:\n",
    "        '''for sample_pred_in in training_samples_pred_in:\n",
    "            sample_pred_in = torch.reshape(sample_pred_in,(1,60*19*4)) #need to reshape to this for our model\n",
    "            sample_pred_in = sample_pred_in.type(torch.FloatTensor)\n",
    "            sample_pred_out = model(sample_pred_in) #will have size 1x (60*30*4)\n",
    "            sample_pred_out = torch.reshape(sample_pred_out,(1,60,30,4))\n",
    "            for vehicle in sample_pred_out[0]:\n",
    "                for time_step in vehicle:\n",
    "                    training_samples_pred_out_posx.append(time_step[0].item())\n",
    "                    training_samples_pred_out_posy.append(time_step[1].item())\n",
    "                    training_samples_pred_out_velx.append(time_step[2].item())\n",
    "                    training_samples_pred_out_vely.append(time_step[3].item())\n",
    "        \n",
    "        t = numpy.linspace(0, len(training_samples_pred_out_posx), endpoint=True)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.plot(t,training_samples_pred_out_posx,t,training_samples_target_posx)\n",
    "        plt.title(\"Training Sample comparison x-pos graph\")\n",
    "        plt.xlabel(\"indices\")\n",
    "        plt.ylabel(\"Coordinate Val\")\n",
    "        plt.show()\n",
    "\n",
    "        s = numpy.linspace(0, len(train_samples_pred_out_posx), endpoint=True)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.plot(s,training_samples_pred_out_posy,s,training_samples_target_posy)\n",
    "        plt.title(\"Training Sample comparison y-pos graph\")\n",
    "        plt.xlabel(\"indices\")\n",
    "        plt.ylabel(\"Coordinate Val\")\n",
    "        plt.show()\n",
    "\n",
    "        v = numpy.linspace(0, len(train_samples_pred_out_posx), endpoint=True)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.plot(v,training_samples_pred_out_velx,v,training_samples_target_velx)\n",
    "        plt.title(\"Training Sample comparison x-vel graph\")\n",
    "        plt.xlabel(\"indices\")\n",
    "        plt.ylabel(\"Velocity Value\")\n",
    "        plt.show()\n",
    "\n",
    "        w = numpy.linspace(0, len(train_samples_pred_out_posx), endpoint=True)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.plot(w,training_samples_pred_out_vely,w,training_samples_target_vely)\n",
    "        plt.title(\"Training Sample comparison y-vel graph\")\n",
    "        plt.xlabel(\"indices\")\n",
    "        plt.ylabel(\"Velocity Value\")\n",
    "        plt.show()'''\n",
    "    \n",
    "    print(\"Done with training on epoch \",epoch)\n",
    "    plotLoss(loss_arr,epoch)\n",
    "    \n",
    "    \n",
    "    if epoch == 1:\n",
    "        plotTrainInOutPos(inp_posx_hist,inp_posy_hist,out_posx_hist,out_posy_hist,out_vel_hist,out_vel_target_hist,1000)\n",
    "    \n",
    "    #Begin testing\n",
    "    iterator_test = tqdm(val_loader,total=int(len(val_loader)))\n",
    "    for i_batch,test_batch in enumerate(iterator_test):\n",
    "        predicted_batches = test(model, device, test_batch,epoch)\n",
    "        \n",
    "        if epoch == num_epoch: #if done with the last epoch then we write to file\n",
    "            with open('submission.csv','a',newline='') as f: #append to csv\n",
    "                thewriter = csv.writer(f)\n",
    "                for p_list in predicted_batches:\n",
    "                    thewriter.writerow(p_list)\n",
    "    \n",
    "    \n",
    "    print(\"Done with epoch \",epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
